{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def build_model(model_type, num_features, num_seq_features, \n",
    "                    y_hidden_layer_sizes, y_filter_size, y_dilation_rate,\n",
    "                    n_hidden_layer_sizes, n_filter_size, n_dilation_rate, dropout, \n",
    "                    lstm_hidden_layer_size, num_lstm_layers=None, bidirectional=False):\n",
    "\n",
    "    class EpLinearModel(nn.Module):\n",
    "        def __init__(self, input_size):\n",
    "            super(EpLinearModel, self).__init__()\n",
    "            self.name = \"ep_linear\"\n",
    "            self.linear = nn.Linear(input_size, 1)\n",
    "\n",
    "        def forward(self, Y_ji):\n",
    "            x = self.linear(Y_ji)\n",
    "            return x.squeeze(-1)   \n",
    "    \n",
    "    class EpSeqLinearModel(nn.Module):\n",
    "        def __init__(self, input_size):\n",
    "            super(EpSeqLinearModel, self).__init__()\n",
    "            self.name = \"ep_seq_linear\"\n",
    "            self.linear = nn.Linear(input_size, 1)\n",
    "\n",
    "        def forward(self, Y_ji, N_ji):\n",
    "            x = torch.cat((Y_ji, N_ji), axis=-1)\n",
    "            x = self.linear(x)\n",
    "            return x.squeeze(-1)\n",
    "    \n",
    "    class LSTMModel(nn.Module):\n",
    "        def __init__(self, input_size, hidden_layer_size, num_layers, bidirectional):\n",
    "            super(LSTMModel, self).__init__()\n",
    "            self.name = \"lstm\"\n",
    "            self.lstm = nn.LSTM(input_size, hidden_layer_size, num_layers, bidirectional=bidirectional, batch_first=True)\n",
    "            self.bidirectional_linear = nn.Linear(2 * hidden_layer_size, 1)\n",
    "            self.linear = nn.Linear(hidden_layer_size, 1)\n",
    "            self.bidirectional = bidirectional\n",
    "\n",
    "        def forward(self, Y_ji, N_ji):\n",
    "            x = torch.cat((Y_ji, N_ji), axis=-1)\n",
    "            x, _ = self.lstm(x)\n",
    "            if self.bidirectional:\n",
    "                x = self.bidirectional_linear(x)\n",
    "            else:\n",
    "                x = self.linear(x)\n",
    "            return x.squeeze(-1)\n",
    "\n",
    "    class CNN(nn.Module):\n",
    "        def __init__(self, num_features, num_seq_features, y_hidden_layer_sizes, y_filter_size, y_dilation_rate,\n",
    "                     n_hidden_layer_sizes, n_filter_size, n_dilation_rate, dropout, \n",
    "                     lstm_hidden_layer_size, num_lstm_layers=None, bidirectional=False):\n",
    "            super(CNN, self).__init__()\n",
    "            self.name = \"cnn\"            \n",
    "\n",
    "            self.y_convs = nn.ModuleList()\n",
    "            y_in_channels = num_features\n",
    "            if isinstance(y_filter_size, int):\n",
    "                y_filter_size = [y_filter_size] * len(y_hidden_layer_sizes)\n",
    "            elif isinstance(y_filter_size, list):\n",
    "                current_length = len(y_filter_size)\n",
    "                if current_length < len(y_hidden_layer_sizes):\n",
    "                    # Extend filter_size by repeating its last value to match the target length\n",
    "                    y_filter_size = y_filter_size + [y_filter_size[-1]] * (len(y_hidden_layer_sizes) - current_length)\n",
    "            \n",
    "            y_dilation = 1\n",
    "            for idx, out_channels in enumerate(y_hidden_layer_sizes):\n",
    "                y_padding = ((y_filter_size[idx] - 1) * y_dilation) // 2\n",
    "                if y_dilation_rate > 0:\n",
    "                    self.y_convs.append(\n",
    "                        nn.Conv1d(y_in_channels, out_channels, y_filter_size[idx], stride=1, padding=y_padding, dilation=y_dilation)\n",
    "                    )\n",
    "                    y_dilation *= y_dilation_rate\n",
    "                else:\n",
    "                    self.y_convs.append(\n",
    "                        nn.Conv1d(y_in_channels, out_channels, y_filter_size[idx], stride=1, padding='same')\n",
    "                    )\n",
    "                y_in_channels = out_channels\n",
    "            \n",
    "            \n",
    "            self.n_convs = nn.ModuleList()\n",
    "            n_in_channels = num_seq_features\n",
    "            if isinstance(n_filter_size, int):\n",
    "                n_filter_size = [n_filter_size] * len(n_hidden_layer_sizes)\n",
    "            elif isinstance(n_filter_size, list):\n",
    "                current_length = len(n_filter_size)\n",
    "                if current_length < len(n_hidden_layer_sizes):\n",
    "                    # Extend filter_size by repeating its last value to match the target length\n",
    "                    n_filter_size = n_filter_size + [n_filter_size[-1]] * (len(n_hidden_layer_sizes) - current_length)\n",
    "            \n",
    "\n",
    "            n_dilation = 1\n",
    "            for idx, out_channels in enumerate(n_hidden_layer_sizes):\n",
    "                n_padding = ((n_filter_size[idx] - 1) * n_dilation) // 2\n",
    "                if n_dilation_rate > 0:\n",
    "                    self.n_convs.append(\n",
    "                        nn.Conv1d(n_in_channels, out_channels, n_filter_size[idx], stride=1, padding=n_padding, dilation=n_dilation)\n",
    "                    )\n",
    "                    n_dilation *= n_dilation_rate\n",
    "                else:\n",
    "                    self.n_convs.append(\n",
    "                        nn.Conv1d(n_in_channels, out_channels, n_filter_size[idx], stride=1, padding='same')\n",
    "                    )\n",
    "                n_in_channels = out_channels\n",
    "\n",
    "            self.relu = nn.ReLU()\n",
    "            self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "            # Final convolutional layer to map to a single output channel\n",
    "            # Since the output needs to be (batch_size, seq_len), we map the final features to 1\n",
    "            self.final_conv = nn.Conv1d(y_hidden_layer_sizes[-1] + n_hidden_layer_sizes[-1], 1, 1)  # 1x1 convolution\n",
    "            \n",
    "            if num_lstm_layers > 0:\n",
    "                self.gru = nn.GRU(input_size=y_hidden_layer_sizes[-1] + n_hidden_layer_sizes[-1], hidden_size=lstm_hidden_layer_size, num_layers=num_lstm_layers, bidirectional=bidirectional, batch_first=True)\n",
    "            self.final_linear = nn.Linear(lstm_hidden_layer_size, 1)\n",
    "            self.bidirectional = True\n",
    "            self.final_bidirectional_linear = nn.Linear(lstm_hidden_layer_size*2, 1)\n",
    "            #self.batch_norm = nn.BatchNorm1d(y_hidden_layer_sizes[-1] + n_hidden_layer_sizes[-1])\n",
    "            \n",
    "        def forward(self, Y_ji, N_ji):\n",
    "            Y_ji = Y_ji.permute(0, 2, 1)  \n",
    "            N_ji = N_ji.permute(0, 2, 1)\n",
    "            \n",
    "            for conv in self.y_convs:\n",
    "                Y_ji = conv(Y_ji)\n",
    "                Y_ji = self.relu(Y_ji)\n",
    "                Y_ji = self.dropout(Y_ji)\n",
    "            \n",
    "            for conv in self.n_convs:\n",
    "                N_ji = conv(N_ji)\n",
    "                N_ji = self.relu(N_ji)\n",
    "                N_ji = self.dropout(N_ji)\n",
    "\n",
    "            x = torch.cat((Y_ji, N_ji), 1)\n",
    "            \n",
    "            #x = self.batch_norm(x)\n",
    "            \n",
    "            if num_lstm_layers > 0:\n",
    "                x = x.permute(0,2,1)\n",
    "                x, (h_n, c_n) = self.gru(x)\n",
    "                if self.bidirectional:\n",
    "                    x = self.final_bidirectional_linear(x)\n",
    "                else:\n",
    "                    x = self.final_linear(x)\n",
    "                x = x.squeeze(-1)\n",
    "            \n",
    "            else:\n",
    "                x = self.final_conv(x)\n",
    "                x = x.squeeze(1)  \n",
    "                \n",
    "            return x\n",
    "    \n",
    "    if model_type == 'lstm':\n",
    "        model = LSTMModel(num_features + num_seq_features, lstm_hidden_layer_sizes, num_lstm_layers, bidirectional)\n",
    "    elif model_type == 'ep_seq_linear':\n",
    "        model = EpSeqLinearModel(num_features + num_seq_features)\n",
    "    elif model_type == 'ep_linear':\n",
    "        model = EpLinearModel(num_features)\n",
    "    elif model_type == 'cnn':\n",
    "        model = CNN(num_features, num_seq_features, y_hidden_layer_sizes, y_filter_size, y_dilation_rate, \n",
    "                    n_hidden_layer_sizes, n_filter_size, n_dilation_rate, dropout, lstm_hidden_layer_size,\n",
    "                    num_lstm_layers, bidirectional)\n",
    "    \n",
    "    if cuda_available:\n",
    "        if num_gpus > 1:\n",
    "            print(\"Using\", num_gpus, \"GPUs\")\n",
    "            Dmodel = torch.nn.DataParallel(model)\n",
    "        model = model.to('cuda')\n",
    "\n",
    "    print(model)\n",
    "    \n",
    "    # expected weights are close to 0 which is why 0 initializing weights converges much quicker\n",
    "    if weight_init == 'zero':\n",
    "        with torch.no_grad():\n",
    "            for param in model.parameters():\n",
    "                param.zero_()\n",
    "    \n",
    "    model.double()\n",
    "\n",
    "    return model.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda3 (Python 3.7.6)",
   "language": "python",
   "name": "anaconda3_2020.02"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
