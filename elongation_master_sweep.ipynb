{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Master File w/ hyperparameter sweeping across multiple architectures\"\"\"\n",
    "\"\"\"\n",
    "Restart kernel after running\n",
    "Only need to run once\n",
    "\"\"\"\n",
    "!pip install scikit-learn matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/grid/siepel/home_norepl/hassett/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3553: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhassett\u001b[0m (\u001b[33melongation-net\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  seqnames     start       end strand  ensembl_gene_id  score      ctcf  \\\n",
      "0       15  88623545  88623545      +  ENSG00000181026    0.0 -0.079992   \n",
      "1       15  88623546  88623546      +  ENSG00000181026    0.0 -0.079942   \n",
      "2       15  88623547  88623547      +  ENSG00000181026    0.0 -0.079893   \n",
      "3       15  88623548  88623548      +  ENSG00000181026    0.0 -0.079844   \n",
      "4       15  88623549  88623549      +  ENSG00000181026    0.0 -0.079796   \n",
      "\n",
      "   h3k36me3   h3k4me1  h3k79me2   h3k9me1   h3k9me3  h4k20me1       sj5  \\\n",
      "0 -0.000099  0.348531  4.423451  0.446508 -0.168099  3.232475 -0.028916   \n",
      "1  0.001638  0.352677  4.460072  0.453024 -0.169218  3.259194 -0.028916   \n",
      "2  0.003360  0.356807  4.496664  0.459491 -0.170339  3.285849 -0.028916   \n",
      "3  0.005065  0.360919  4.533223  0.465908 -0.171461  3.312435 -0.028916   \n",
      "4  0.006754  0.365013  4.569743  0.472274 -0.172584  3.338952 -0.028916   \n",
      "\n",
      "        sj3       dms  wgbs      rpts  lambda_alphaj      zeta  \n",
      "0 -0.057178 -0.307549   0.0  0.249626       0.052255  0.993283  \n",
      "1 -0.057178 -0.307549   0.0  0.249626       0.052255  0.992642  \n",
      "2 -0.057178 -0.307549   0.0  0.249626       0.052255  0.992008  \n",
      "3 -0.057178 -0.307549   0.0  0.249626       0.052255  0.991381  \n",
      "4 -0.057178 -0.307549   0.0  0.249626       0.052255  0.990762  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.utils.data as td\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "import wandb\n",
    "\n",
    "froot = './data/k562_samp_epft_norm_test_1.csv'\n",
    "df = pd.read_csv(froot)\n",
    "\n",
    "wandb.login()\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ctcf' 'h3k36me3' 'h3k4me1' 'h3k79me2' 'h3k9me1' 'h3k9me3' 'h4k20me1'\n",
      " 'sj5' 'sj3' 'dms' 'wgbs' 'rpts']\n",
      "Number of Samples: 16182613\n",
      "Number of Features: 12\n",
      "(16182613, 12)\n",
      "CUDA (GPU support) is available: True\n",
      "Number of GPUs available: 1\n"
     ]
    }
   ],
   "source": [
    "column_names = np.array(df.columns)\n",
    "feature_names = column_names[6:-2]\n",
    "num_features = len(feature_names)\n",
    "print(feature_names)\n",
    "num_samples = df.shape[0]\n",
    "\n",
    "# process read counts per gene j, site i\n",
    "X_ji = df['score'].values\n",
    "\n",
    "# process GLM simulated elongation rates\n",
    "Z_ji = df['zeta'].values\n",
    "\n",
    "print(\"Number of Samples: \" + str(num_samples))\n",
    "print(\"Number of Features: \" + str(num_features))\n",
    "\n",
    "#Y_ji is a list of samples containing lists of their feature values\n",
    "    # [   \n",
    "    #   sample_1: [feat_1, feat_2,...,feat_n],\n",
    "    #   sample_2: [feat_1, feat_2,...,feat_n],\n",
    "    # ]\n",
    "\n",
    "Y_ji = df.iloc[:, 6:-2].values\n",
    "Y_ji_shape = Y_ji.shape\n",
    "print(Y_ji.shape)\n",
    "\n",
    "# read depth * initiation rate values per gene j\n",
    "C_j = df['lambda_alphaj'].values\n",
    "\n",
    "gene_ids = df['ensembl_gene_id'].values\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(\"CUDA (GPU support) is available:\", cuda_available)\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(\"Number of GPUs available:\", num_gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'grid'\n",
    "}\n",
    "metric = {\n",
    "    'name': 'valid_neural_net_loss',\n",
    "    'goal': 'minimize'   \n",
    "    }\n",
    "\n",
    "sweep_config['metric'] = metric\n",
    "\n",
    "parameters_dict = {\n",
    "    'optimizer': {\n",
    "        'values': ['adam']#,'sgd']\n",
    "    },\n",
    "    'learn_rate': {\n",
    "        'values': [1e-2, 1e-3, 1e-4, 1e-6, 1e-8]\n",
    "    },\n",
    "    'momentum': {\n",
    "        'values': [0]#, 0.9]\n",
    "    },\n",
    "    'train_batch_size': {\n",
    "        'values': [1]\n",
    "    },\n",
    "    'train_use_sliding_window': {\n",
    "        'values': [False]\n",
    "    },\n",
    "    'train_window_size': {\n",
    "        'values': [0]\n",
    "    },\n",
    "    'train_stride': {\n",
    "        'values': [0]\n",
    "    },\n",
    "    'val_batch_size': {\n",
    "        'values': [1]\n",
    "    },\n",
    "    'val_use_sliding_window': {\n",
    "        'values': [False]\n",
    "    },\n",
    "    'val_window_size': {\n",
    "        'values': [0]\n",
    "    },\n",
    "    'val_stride': {\n",
    "        'values': [0]\n",
    "    },\n",
    "    'model_type': {\n",
    "        'values': ['lstm']\n",
    "    },\n",
    "    'bidirectional': {\n",
    "        'values': [False, True]\n",
    "    },\n",
    "    'lstm_hidden_layer_size': {\n",
    "        'values': [100, 50, 200, 500]\n",
    "    },\n",
    "    'num_lstm_layers': {\n",
    "        'values': [1,2]\n",
    "    },\n",
    "    'dense_hidden_layer_sizes': {\n",
    "        'values': [[9]]#[[9, 6], [50, 25], [100, 50], [200, 100, 50], [100, 50, 25], [100, 50, 25, 6]]\n",
    "    },\n",
    "    'dense_activation_func': {\n",
    "        'values': ['relu']#, 'leakyrelu']\n",
    "    },\n",
    "    'weight_init': {\n",
    "        'values': [None]#, 'zero']\n",
    "    }\n",
    "}\n",
    "\n",
    "parameters_dict.update({\n",
    "    'epochs': {\n",
    "        'value': 20}\n",
    "    })\n",
    "\n",
    "sweep_config['parameters'] = parameters_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 38ix900q\n",
      "Sweep URL: https://wandb.ai/elongation-net/elongation-net/sweeps/38ix900q\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"elongation-net\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneDataset(Dataset):\n",
    "    def __init__(self, grouped_data, use_sliding_window=False, window_size=None, stride=None):\n",
    "        self.grouped_data = grouped_data\n",
    "        self.use_sliding_window = use_sliding_window\n",
    "        self.window_size = window_size\n",
    "        self.stride = stride\n",
    "        self.segments = []\n",
    "\n",
    "        if self.use_sliding_window and window_size is not None and stride is not None:\n",
    "            self._create_segments()\n",
    "        else:\n",
    "            self._prepare_full_genes()\n",
    "        \n",
    "    def _create_segments(self):\n",
    "        for gene_id, group in self.grouped_data:\n",
    "            gene_length = len(group)\n",
    "            for start_idx in range(0, gene_length - self.window_size + 1, self.stride):\n",
    "                end_idx = start_idx + self.window_size\n",
    "                segment = group.iloc[start_idx:end_idx]\n",
    "                self.segments.append((gene_id, segment))\n",
    "    \n",
    "    def _prepare_full_genes(self):\n",
    "        for gene_id, group in self.grouped_data:\n",
    "            self.segments.append((gene_id, group))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.segments)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        gene_id, segment = self.segments[idx]\n",
    "        \n",
    "        y_ji_array = np.array(segment['Y_ji'].tolist()).reshape(-1, 12)\n",
    "        y_ji_tensor = torch.tensor(y_ji_array, dtype=torch.float64)\n",
    "        \n",
    "        data = segment.drop(columns=['GeneId', 'dataset', 'Y_ji'])\n",
    "        tensor_data = torch.tensor(data.values, dtype=torch.float64)\n",
    "        \n",
    "        result = {\n",
    "            'GeneId': gene_id,\n",
    "            'Y_ji': y_ji_tensor,\n",
    "            'gene_length': len(segment)\n",
    "        }\n",
    "        for col in data.columns:\n",
    "            result[col] = tensor_data[:, data.columns.get_loc(col)]\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size: 12713808\n",
      "val data size: 1798949\n",
      "test data size: 1669856\n",
      "train # genes: 415\n",
      "val # genes: 52\n",
      "test # genes: 52\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'GeneId': gene_ids,\n",
    "    'Y_ji': [row for row in Y_ji],\n",
    "    'X_ji': X_ji,\n",
    "    'C_j': C_j,\n",
    "    'Z_ji': Z_ji\n",
    "})\n",
    "\n",
    "grouped = data.groupby('GeneId')\n",
    "\n",
    "# split by gene into train, val, test sets\n",
    "train_idx, temp_idx = train_test_split(list(grouped.groups.keys()), test_size=0.2, random_state=42)\n",
    "val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, random_state=42)\n",
    "\n",
    "# create dictionary mapping each gene id to its assigned train, val, test dataset labels\n",
    "dataset_mapping = {gene_id: 'train' for gene_id in train_idx}\n",
    "dataset_mapping.update({gene_id: 'val' for gene_id in val_idx})\n",
    "dataset_mapping.update({gene_id: 'test' for gene_id in test_idx})\n",
    "\n",
    "# filter rows based on assigned dataset field\n",
    "data['dataset'] = data['GeneId'].map(dataset_mapping)\n",
    "train_data = data[data['dataset'] == 'train']\n",
    "valid_data = data[data['dataset'] == 'val']\n",
    "test_data = data[data['dataset'] == 'test']\n",
    "\n",
    "\n",
    "print(\"train data size: \" + str(len(train_data)))\n",
    "print(\"val data size: \" + str(len(valid_data)))\n",
    "print(\"test data size: \" + str(len(test_data)))\n",
    "\n",
    "train_data = train_data.groupby('GeneId')\n",
    "valid_data = valid_data.groupby('GeneId')\n",
    "test_data = test_data.groupby('GeneId')\n",
    "print(\"train # genes: \" + str(len(train_data)))\n",
    "print(\"val # genes: \" + str(len(valid_data)))\n",
    "print(\"test # genes: \" + str(len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(train_data, batch_size, use_sliding_window=False, window_size=None, stride=None):\n",
    "    dataset = GeneDataset(train_data, use_sliding_window, window_size, stride)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, num_workers=7, shuffle=False, pin_memory=True)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def build_model(model_type, num_lstm_layers, lstm_hidden_layer_size, bidirectional, \n",
    "                dense_hidden_layer_sizes, dense_activation_func, weight_init):\n",
    "    \n",
    "    class LSTMModel(nn.Module):\n",
    "        def __init__(self, input_size, hidden_layer_size, output_size, num_layers, bidirectional):\n",
    "            super(LSTMModel, self).__init__()\n",
    "            self.lstm = nn.LSTM(input_size, hidden_layer_size, num_layers, bidirectional=bidirectional, batch_first=True)\n",
    "            self.bidirectional = bidirectional\n",
    "            self.bidirectional_linear = nn.Linear(2 * hidden_layer_size, output_size)\n",
    "            self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x, _ = self.lstm(x)\n",
    "            if self.bidirectional:\n",
    "                x = self.bidirectional_linear(x)\n",
    "            else:\n",
    "                x = self.linear(x)\n",
    "            return x\n",
    "        \n",
    "    class DenseNet(nn.Module):\n",
    "        def __init__(self, input_size, layer_sizes, output_size, activation='relu'):\n",
    "            super(DenseNet, self).__init__()\n",
    "            \n",
    "            layers = []\n",
    "\n",
    "            # Define the input layer\n",
    "            prev_size = input_size\n",
    "\n",
    "            for size in layer_sizes:\n",
    "                layers.append(nn.Linear(prev_size, size))\n",
    "\n",
    "                if activation.lower() == 'leakyrelu':\n",
    "                    layers.append(nn.LeakyReLU())\n",
    "                elif activation.lower() == 'relu':\n",
    "                    layers.append(nn.ReLU())\n",
    "                else:\n",
    "                    raise ValueError(\"Unsupported activation function\")\n",
    "\n",
    "                prev_size = size\n",
    "\n",
    "            layers.append(nn.Linear(prev_size, output_size))\n",
    "\n",
    "            self.layers = nn.Sequential(*layers)\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.layers(x)\n",
    "    \n",
    "    if model_type == 'lstm':\n",
    "        model = LSTMModel(num_features, lstm_hidden_layer_size, 1, num_lstm_layers, bidirectional)\n",
    "    elif model_type == 'linear':\n",
    "        model = nn.Linear(num_features, 1, bias=False)\n",
    "    elif model_type == 'dense':\n",
    "        model = DenseNet(num_features, dense_hidden_layer_sizes, 1, dense_activation_func)\n",
    "    \n",
    "    if cuda_available:\n",
    "        if num_gpus > 1:\n",
    "            print(\"Using\", num_gpus, \"GPUs\")\n",
    "            model = torch.nn.DataParallel(model)\n",
    "        model = model.to('cuda')\n",
    "\n",
    "    print(model)\n",
    "\n",
    "    first_param_device = next(model.parameters()).device\n",
    "    print(\"Model is on device:\", first_param_device)\n",
    "    \n",
    "    # expected weights are close to 0 which is why 0 initializing weights converges much quicker\n",
    "    if weight_init == 'zero':\n",
    "        with torch.no_grad():\n",
    "            for param in model.parameters():\n",
    "                param.zero_()\n",
    "    \n",
    "    model.double()\n",
    "\n",
    "    return model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_optimizer(network, optimizer, learning_rate, momentum):\n",
    "    if optimizer == \"sgd\":\n",
    "        optimizer = optim.SGD(network.parameters(),\n",
    "                              lr=learning_rate, momentum=momentum)\n",
    "        \n",
    "    # Adam optimizer adapts the learning rate for each parameter individually\n",
    "    elif optimizer == \"adam\":\n",
    "        optimizer = optim.Adam(network.parameters(),\n",
    "                               lr=learning_rate)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_epoch(model, loader, loss_fn):\n",
    "    model.eval()\n",
    "    total_neural_net_loss = 0\n",
    "    total_glm_loss = 0\n",
    "    neural_net_zeta = []\n",
    "    glm_zeta = []\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(loader):\n",
    "            Y_ji_batch = batch['Y_ji'].to(device)\n",
    "            X_ji_batch = batch['X_ji'].to(device)\n",
    "            C_j_batch = batch['C_j'].to(device)\n",
    "            Z_ji_batch = batch['Z_ji'].to(device)\n",
    "            lengths = batch['gene_length'].to(device)\n",
    "            \n",
    "            outputs = model(Y_ji_batch)\n",
    "            neural_net_loss = loss_fn(X_ji_batch, C_j_batch, outputs.squeeze(2), lengths)\n",
    "            glm_loss = loss_fn(X_ji_batch, C_j_batch, Z_ji_batch, lengths)\n",
    "\n",
    "            total_neural_net_loss +=  neural_net_loss.item()\n",
    "            total_glm_loss += glm_loss.item()\n",
    "            \n",
    "            # store all predictions in list\n",
    "            neural_net_zeta.append(torch.exp(outputs.cpu()[0]))\n",
    "            glm_zeta.append(batch['Z_ji'][0])\n",
    "    \n",
    "    # calculate average loss across all batches\n",
    "    avg_neural_net_loss = total_neural_net_loss / len(loader)\n",
    "    avg_glm_loss = total_glm_loss / len(loader)\n",
    "    \n",
    "    neural_net_zeta = torch.cat(neural_net_zeta, dim=0)\n",
    "    glm_zeta = torch.cat(glm_zeta, dim=0)\n",
    "    \n",
    "    return avg_neural_net_loss, avg_glm_loss, neural_net_zeta, glm_zeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, loss_fn):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for idx, batch in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "        Y_ji_batch = batch['Y_ji'].to(device)\n",
    "        X_ji_batch = batch['X_ji'].to(device)\n",
    "        C_j_batch = batch['C_j'].to(device)\n",
    "        lengths = batch['gene_length'].to(device)\n",
    "        \n",
    "        outputs = model(Y_ji_batch)\n",
    "        loss = loss_fn(X_ji_batch, C_j_batch, outputs.squeeze(2), lengths)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # calculate average loss across all batches\n",
    "        total_loss += loss.item()\n",
    "    avg_train_loss = total_loss / len(loader)\n",
    "    \n",
    "    return avg_train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomLoss, self).__init__()\n",
    "\n",
    "    def forward(self, X_ji, C_j, rho_ji, lengths):\n",
    "        C_j_value = C_j[0]\n",
    "        loss = X_ji * rho_ji + C_j_value * torch.exp(-rho_ji) - X_ji * torch.log(C_j_value)\n",
    "        \n",
    "        # normalize loss by sequence length\n",
    "        loss_sum = loss.sum(dim=1)\n",
    "        normalized_loss = loss_sum / lengths.float()\n",
    "        \n",
    "        # calculate average loss within each batch\n",
    "        return (normalized_loss).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "increase_cut=1\n",
    "\n",
    "def train(config=None):\n",
    "    with wandb.init(config=config):\n",
    "        config = wandb.config\n",
    "        model = build_model(config.model_type, config.num_lstm_layers, config.lstm_hidden_layer_size, \n",
    "                            config.bidirectional, config.dense_hidden_layer_sizes, config.dense_activation_func, \n",
    "                            config.weight_init)\n",
    "        train_loader = build_dataset(train_data, config.train_batch_size, config.train_use_sliding_window, \n",
    "                                     config.train_window_size, config.train_stride)\n",
    "        valid_loader = build_dataset(valid_data, config.val_batch_size, config.val_use_sliding_window, \n",
    "                                     config.val_window_size, config.val_stride)\n",
    "        optimizer = build_optimizer(model, config.optimizer, config.learn_rate, config.momentum)\n",
    "        \n",
    "        loss_fn = CustomLoss()\n",
    "        loss_neural_net_train = [0] * config.epochs\n",
    "        loss_neural_net_valid = [0] * config.epochs\n",
    "        loss_glm_valid = [0] * config.epochs\n",
    "        \n",
    "        # scheduler to reduce learning rate by half when new validation loss > old validation loss\n",
    "        old_neural_net_valid_loss = float('inf')\n",
    "        learning_rate_decreased = False\n",
    "        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=1, verbose=True)\n",
    "\n",
    "        for epoch in range(config.epochs):\n",
    "            print(f'Epoch {epoch+1}')\n",
    "            \n",
    "            train_loss = train_epoch(model, train_loader, optimizer, loss_fn)\n",
    "            loss_neural_net_train[epoch] = train_loss\n",
    "            print(\"train loss: \"+ str(train_loss))\n",
    "            \n",
    "            valid_neural_net_loss, valid_glm_loss, neural_net_zeta, glm_zeta = valid_epoch(model, valid_loader, loss_fn)\n",
    "            loss_neural_net_valid[epoch] = valid_neural_net_loss\n",
    "            loss_glm_valid[epoch] = valid_glm_loss\n",
    "            print(\"valid neural net loss: \"+ str(valid_neural_net_loss))\n",
    "            print(\"valid glm loss: \"+ str(valid_glm_loss))\n",
    "            \n",
    "            # calculate metrics\n",
    "            mae = F.l1_loss(neural_net_zeta.squeeze(), glm_zeta)\n",
    "            mse = F.mse_loss(neural_net_zeta.squeeze(), glm_zeta)\n",
    "            correlation_coefficient = np.corrcoef(glm_zeta, neural_net_zeta.squeeze())[0, 1]\n",
    "            print(\"Correlation Coefficient:\", correlation_coefficient)\n",
    "            print(f\"Mean Absolute Error: {mae.item():.4f}\")\n",
    "            print(f\"Mean Squared Error: {mse.item():.4f}\")\n",
    "            \n",
    "            \n",
    "            wandb.log({\"epoch\": epoch, \"train_loss\": train_loss, \"valid_neural_net_loss\": valid_neural_net_loss,\n",
    "                       \"valid_glm_loss\": valid_glm_loss, \"corr_coeff\": correlation_coefficient, \"mae\": mae.item(), \n",
    "                       \"mse\": mse.item()})\n",
    "            \n",
    "            # early stopping if loss is not improving after reducing learning rate\n",
    "            if learning_rate_decreased and valid_neural_net_loss - old_neural_net_valid_loss < increase_cut:\n",
    "                break\n",
    "                \n",
    "            # reduce learning rate if new loss > old loss\n",
    "            learning_rate_decreased = False\n",
    "            if valid_neural_net_loss > old_neural_net_valid_loss:\n",
    "                optimizer.param_groups[0]['lr'] *= 0.5\n",
    "                print(f\"Reduced learning rate to {optimizer.param_groups[0]['lr']}\")\n",
    "                learning_rate_decreased=True\n",
    "            old_train_loss = train_loss\n",
    "            scheduler.step(train_loss)\n",
    "            \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: j3v2lzky with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_activation_func: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_hidden_layer_sizes: [9]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearn_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlstm_hidden_layer_size: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_type: lstm\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_lstm_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrain_batch_size: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrain_stride: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrain_use_sliding_window: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrain_window_size: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_batch_size: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_stride: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_use_sliding_window: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_window_size: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_init: None\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/grid/siepel/home_norepl/hassett/ElongationNet/wandb/run-20240124_232055-j3v2lzky</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/elongation-net/elongation-net/runs/j3v2lzky' target=\"_blank\">royal-sweep-1</a></strong> to <a href='https://wandb.ai/elongation-net/elongation-net' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/elongation-net/elongation-net/sweeps/38ix900q' target=\"_blank\">https://wandb.ai/elongation-net/elongation-net/sweeps/38ix900q</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/elongation-net/elongation-net' target=\"_blank\">https://wandb.ai/elongation-net/elongation-net</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/elongation-net/elongation-net/sweeps/38ix900q' target=\"_blank\">https://wandb.ai/elongation-net/elongation-net/sweeps/38ix900q</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/elongation-net/elongation-net/runs/j3v2lzky' target=\"_blank\">https://wandb.ai/elongation-net/elongation-net/runs/j3v2lzky</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMModel(\n",
      "  (lstm): LSTM(12, 100, batch_first=True)\n",
      "  (bidirectional_linear): Linear(in_features=200, out_features=1, bias=True)\n",
      "  (linear): Linear(in_features=100, out_features=1, bias=True)\n",
      ")\n",
      "Model is on device: cuda:0\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.13111436941316415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid neural net loss: 0.10792631501847524\n",
      "valid glm loss: 0.11788066345250017\n",
      "Correlation Coefficient: 0.7961438166823341\n",
      "Mean Absolute Error: 0.2057\n",
      "Mean Squared Error: 0.0718\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.130934787130978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid neural net loss: 0.10780420935176356\n",
      "valid glm loss: 0.11788066345250017\n",
      "Correlation Coefficient: 0.802156090155867\n",
      "Mean Absolute Error: 0.1648\n",
      "Mean Squared Error: 0.0437\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.13066260391211826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid neural net loss: 0.10775537692635401\n",
      "valid glm loss: 0.11788066345250017\n",
      "Correlation Coefficient: 0.8039156649373339\n",
      "Mean Absolute Error: 0.1899\n",
      "Mean Squared Error: 0.0649\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.13055745501330066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid neural net loss: 0.10776295148366104\n",
      "valid glm loss: 0.11788066345250017\n",
      "Correlation Coefficient: 0.7752066699703576\n",
      "Mean Absolute Error: 0.2213\n",
      "Mean Squared Error: 0.0824\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.13050960622797675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid neural net loss: 0.10777136228795235\n",
      "valid glm loss: 0.11788066345250017\n",
      "Correlation Coefficient: 0.7866940598781607\n",
      "Mean Absolute Error: 0.2238\n",
      "Mean Squared Error: 0.0864\n",
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.1305285902851448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid neural net loss: 0.10780914489259093\n",
      "valid glm loss: 0.11788066345250017\n",
      "Correlation Coefficient: 0.7691587496269254\n",
      "Mean Absolute Error: 0.2440\n",
      "Mean Squared Error: 0.1006\n",
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.1304420737452523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid neural net loss: 0.10779100989052835\n",
      "valid glm loss: 0.11788066345250017\n",
      "Correlation Coefficient: 0.785958815762216\n",
      "Mean Absolute Error: 0.2492\n",
      "Mean Squared Error: 0.1082\n",
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.13049246964047806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid neural net loss: 0.10787025900064383\n",
      "valid glm loss: 0.11788066345250017\n",
      "Correlation Coefficient: 0.7733197604414013\n",
      "Mean Absolute Error: 0.2588\n",
      "Mean Squared Error: 0.1185\n",
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.13041539350724726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid neural net loss: 0.10792883050560079\n",
      "valid glm loss: 0.11788066345250017\n",
      "Correlation Coefficient: 0.7826602090141119\n",
      "Mean Absolute Error: 0.2515\n",
      "Mean Squared Error: 0.1106\n",
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.13036683325145984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid neural net loss: 0.10813468756005092\n",
      "valid glm loss: 0.11788066345250017\n",
      "Correlation Coefficient: 0.7826634949889147\n",
      "Mean Absolute Error: 0.2579\n",
      "Mean Squared Error: 0.1188\n",
      "Epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.13033283482725297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid neural net loss: 0.10805348678463501\n",
      "valid glm loss: 0.11788066345250017\n",
      "Correlation Coefficient: 0.7721446799706022\n",
      "Mean Absolute Error: 0.2587\n",
      "Mean Squared Error: 0.1201\n",
      "Epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.13030712251827187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid neural net loss: 0.10793736456947503\n",
      "valid glm loss: 0.11788066345250017\n",
      "Correlation Coefficient: 0.7473709570266097\n",
      "Mean Absolute Error: 0.2604\n",
      "Mean Squared Error: 0.1238\n",
      "Epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.13027559785237663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid neural net loss: 0.10801463890989974\n",
      "valid glm loss: 0.11788066345250017\n",
      "Correlation Coefficient: 0.7743646006057026\n",
      "Mean Absolute Error: 0.2580\n",
      "Mean Squared Error: 0.1213\n",
      "Epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.13030371081994013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid neural net loss: 0.10797716742551497\n",
      "valid glm loss: 0.11788066345250017\n",
      "Correlation Coefficient: 0.7683911516827117\n",
      "Mean Absolute Error: 0.2701\n",
      "Mean Squared Error: 0.1364\n",
      "Epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.13022049541798586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid neural net loss: 0.10798696517334669\n",
      "valid glm loss: 0.11788066345250017\n",
      "Correlation Coefficient: 0.7581797855185368\n",
      "Mean Absolute Error: 0.2718\n",
      "Mean Squared Error: 0.1345\n",
      "Epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda3 (Python 3.7.6)",
   "language": "python",
   "name": "anaconda3_2020.02"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
