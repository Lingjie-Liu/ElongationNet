{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Testing/Debugging File \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Restart kernel after running\n",
    "Only need to run once\n",
    "\"\"\"\n",
    "!pip install scikit-learn matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.utils.data as td\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "\n",
    "froot = './data/k562_samp_epft_norm_test_1.csv'\n",
    "df = pd.read_csv(froot)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  seqnames     start       end strand  ensembl_gene_id  score      ctcf  \\\n",
      "0       15  88623545  88623545      +  ENSG00000181026    0.0 -0.079992   \n",
      "1       15  88623546  88623546      +  ENSG00000181026    0.0 -0.079942   \n",
      "2       15  88623547  88623547      +  ENSG00000181026    0.0 -0.079893   \n",
      "3       15  88623548  88623548      +  ENSG00000181026    0.0 -0.079844   \n",
      "4       15  88623549  88623549      +  ENSG00000181026    0.0 -0.079796   \n",
      "\n",
      "   h3k36me3   h3k4me1  h3k79me2   h3k9me1   h3k9me3  h4k20me1       sj5  \\\n",
      "0 -0.000099  0.348531  4.423451  0.446508 -0.168099  3.232475 -0.028916   \n",
      "1  0.001638  0.352677  4.460072  0.453024 -0.169218  3.259194 -0.028916   \n",
      "2  0.003360  0.356807  4.496664  0.459491 -0.170339  3.285849 -0.028916   \n",
      "3  0.005065  0.360919  4.533223  0.465908 -0.171461  3.312435 -0.028916   \n",
      "4  0.006754  0.365013  4.569743  0.472274 -0.172584  3.338952 -0.028916   \n",
      "\n",
      "        sj3       dms  wgbs      rpts  lambda_alphaj      zeta  \n",
      "0 -0.057178 -0.307549   0.0  0.249626       0.052255  0.993283  \n",
      "1 -0.057178 -0.307549   0.0  0.249626       0.052255  0.992642  \n",
      "2 -0.057178 -0.307549   0.0  0.249626       0.052255  0.992008  \n",
      "3 -0.057178 -0.307549   0.0  0.249626       0.052255  0.991381  \n",
      "4 -0.057178 -0.307549   0.0  0.249626       0.052255  0.990762  \n",
      "['ctcf' 'h3k36me3' 'h3k4me1' 'h3k79me2' 'h3k9me1' 'h3k9me3' 'h4k20me1'\n",
      " 'sj5' 'sj3' 'dms' 'wgbs' 'rpts']\n",
      "Number of Samples: 16182613\n",
      "Number of Features: 12\n",
      "(16182613, 12)\n",
      "CUDA (GPU support) is available: True\n",
      "Number of GPUs available: 1\n"
     ]
    }
   ],
   "source": [
    "column_names = np.array(df.columns)\n",
    "feature_names = column_names[6:-2]\n",
    "num_features = len(feature_names)\n",
    "print(feature_names)\n",
    "num_samples = df.shape[0]\n",
    "\n",
    "# process read counts per gene j, site i\n",
    "X_ji = df['score'].values\n",
    "\n",
    "# process GLM simulated elongation rates\n",
    "Z_ji = df['zeta'].values\n",
    "\n",
    "print(\"Number of Samples: \" + str(num_samples))\n",
    "print(\"Number of Features: \" + str(num_features))\n",
    "\n",
    "#Y_ji is a list of samples containing lists of their feature values\n",
    "    # [   \n",
    "    #   sample_1: [feat_1, feat_2,...,feat_n],\n",
    "    #   sample_2: [feat_1, feat_2,...,feat_n],\n",
    "    # ]\n",
    "\n",
    "Y_ji = df.iloc[:, 6:-2].values\n",
    "Y_ji_shape = Y_ji.shape\n",
    "print(Y_ji.shape)\n",
    "\n",
    "# read depth * initiation rate values per gene j\n",
    "C_j = df['lambda_alphaj'].values\n",
    "\n",
    "gene_ids = df['ensembl_gene_id'].values\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(\"CUDA (GPU support) is available:\", cuda_available)\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(\"Number of GPUs available:\", num_gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneDataset(Dataset):\n",
    "    def __init__(self, grouped_data, use_sliding_window=False, window_size=None, stride=None):\n",
    "        self.grouped_data = grouped_data\n",
    "        self.use_sliding_window = use_sliding_window\n",
    "        self.window_size = window_size\n",
    "        self.stride = stride\n",
    "        self.segments = []\n",
    "\n",
    "        if self.use_sliding_window and window_size is not None and stride is not None:\n",
    "            self._create_segments()\n",
    "        else:\n",
    "            self._prepare_full_genes()\n",
    "        \n",
    "    def _create_segments(self):\n",
    "        for gene_id, group in self.grouped_data:\n",
    "            gene_length = len(group)\n",
    "            for start_idx in range(0, gene_length - self.window_size + 1, self.stride):\n",
    "                end_idx = start_idx + self.window_size\n",
    "                segment = group.iloc[start_idx:end_idx]\n",
    "                self.segments.append((gene_id, segment))\n",
    "    \n",
    "    def _prepare_full_genes(self):\n",
    "        for gene_id, group in self.grouped_data:\n",
    "            self.segments.append((gene_id, group))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.segments)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        gene_id, segment = self.segments[idx]\n",
    "        \n",
    "        y_ji_array = np.array(segment['Y_ji'].tolist()).reshape(-1, 12)\n",
    "        y_ji_tensor = torch.tensor(y_ji_array, dtype=torch.float64)\n",
    "        \n",
    "        data = segment.drop(columns=['GeneId', 'dataset', 'Y_ji'])\n",
    "        tensor_data = torch.tensor(data.values, dtype=torch.float64)\n",
    "        \n",
    "        result = {\n",
    "            'GeneId': gene_id,\n",
    "            'Y_ji': y_ji_tensor,\n",
    "            'gene_length': len(segment)\n",
    "        }\n",
    "        for col in data.columns:\n",
    "            result[col] = tensor_data[:, data.columns.get_loc(col)]\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size: 12713808\n",
      "val data size: 1798949\n",
      "test data size: 1669856\n",
      "train data size: 415\n",
      "val data size: 52\n",
      "test data size: 52\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'GeneId': gene_ids,\n",
    "    'Y_ji': [row for row in Y_ji],\n",
    "    'X_ji': X_ji,\n",
    "    'C_j': C_j,\n",
    "    'Z_ji': Z_ji\n",
    "})\n",
    "\n",
    "grouped = data.groupby('GeneId')\n",
    "\n",
    "# split by gene into train, val, test sets\n",
    "train_idx, temp_idx = train_test_split(list(grouped.groups.keys()), test_size=0.2, random_state=42)\n",
    "val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, random_state=42)\n",
    "\n",
    "# create dictionary mapping each gene id to its assigned train, val, test dataset labels\n",
    "dataset_mapping = {gene_id: 'train' for gene_id in train_idx}\n",
    "dataset_mapping.update({gene_id: 'val' for gene_id in val_idx})\n",
    "dataset_mapping.update({gene_id: 'test' for gene_id in test_idx})\n",
    "\n",
    "# filter rows based on assigned dataset field\n",
    "data['dataset'] = data['GeneId'].map(dataset_mapping)\n",
    "train_data = data[data['dataset'] == 'train']\n",
    "valid_data = data[data['dataset'] == 'val']\n",
    "test_data = data[data['dataset'] == 'test']\n",
    "\n",
    "print(\"train data size: \" + str(len(train_data)))\n",
    "print(\"val data size: \" + str(len(valid_data)))\n",
    "print(\"test data size: \" + str(len(test_data)))\n",
    "\n",
    "train_data = train_data.groupby('GeneId')\n",
    "valid_data = valid_data.groupby('GeneId')\n",
    "test_data = test_data.groupby('GeneId')\n",
    "print(\"train # genes: \" + str(len(train_data)))\n",
    "print(\"val # genes: \" + str(len(valid_data)))\n",
    "print(\"test # genes: \" + str(len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(train_data, batch_size, use_sliding_window=False, window_size=None, stride=None):\n",
    "    dataset = GeneDataset(train_data, use_sliding_window, window_size, stride)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, num_workers=7, shuffle=False, pin_memory=True)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def build_model(model_type, num_layers, hidden_layer_size, bidirectional, weight_init):\n",
    "    \n",
    "    class LSTMModel(nn.Module):\n",
    "        def __init__(self, input_size, hidden_layer_size, output_size, num_layers, bidirectional):\n",
    "            super(LSTMModel, self).__init__()\n",
    "            self.lstm = nn.LSTM(input_size, hidden_layer_size, num_layers, bidirectional=bidirectional, batch_first=True)\n",
    "            self.bidirectional_linear = nn.Linear(2 * hidden_layer_size, output_size)\n",
    "            self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x, _ = self.lstm(x)\n",
    "            if self.bidirectional:\n",
    "                x = self.bidirectional_linear(x)\n",
    "            else:\n",
    "                x = self.linear(x)\n",
    "            return x\n",
    "    \n",
    "    if model_type == 'lstm':\n",
    "        model = LSTMModel(num_features, hidden_layer_size, 1, num_layers, bidirectional)\n",
    "    elif model_type == 'linear':\n",
    "        model = nn.Linear(num_features, 1, bias=False)\n",
    "    \n",
    "    if cuda_available:\n",
    "        if num_gpus > 1:\n",
    "            print(\"Using\", num_gpus, \"GPUs\")\n",
    "            model = torch.nn.DataParallel(model)\n",
    "        model = model.to('cuda')\n",
    "\n",
    "    print(model)\n",
    "    \n",
    "    \"\"\"\n",
    "    # print # model parameters\n",
    "    arr = torch.randn((1,12,2000)).to(device)\n",
    "    print(model(arr).shape)\n",
    "    nparm = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(\"Number of parameters: \" + str(nparm))\n",
    "    \"\"\"\n",
    "\n",
    "    first_param_device = next(model.parameters()).device\n",
    "    print(\"Model is on device:\", first_param_device)\n",
    "    \n",
    "    # expected weights are close to 0 which is why 0 initializing weights converges much quicker\n",
    "    if weight_init == 'zero':\n",
    "        with torch.no_grad():\n",
    "            for param in model.parameters():\n",
    "                param.zero_()\n",
    "    \n",
    "    model.double()\n",
    "\n",
    "    return model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_optimizer(network, optimizer, learning_rate, momentum):\n",
    "    if optimizer == \"sgd\":\n",
    "        optimizer = optim.SGD(network.parameters(),\n",
    "                              lr=learning_rate, momentum=momentum)\n",
    "        \n",
    "    # Adam optimizer adapts the learning rate for each parameter individually\n",
    "    elif optimizer == \"adam\":\n",
    "        optimizer = optim.Adam(network.parameters(),\n",
    "                               lr=learning_rate)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_epoch(model, loader, loss_fn):\n",
    "    model.eval()\n",
    "    total_neural_net_loss = 0\n",
    "    total_glm_loss = 0\n",
    "    neural_net_zeta = []\n",
    "    glm_zeta = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(loader):\n",
    "            Y_ji_batch = batch['Y_ji'].to(device)\n",
    "            X_ji_batch = batch['X_ji'].to(device)\n",
    "            C_j_batch = batch['C_j'].to(device)\n",
    "            Z_ji_batch = batch['Z_ji'].to(device)\n",
    "            lengths = batch['gene_length'].to(device)\n",
    "            \n",
    "            outputs = model(Y_ji_batch)\n",
    "            neural_net_loss = loss_fn(X_ji_batch, C_j_batch, outputs.squeeze(2), lengths)\n",
    "            glm_loss = loss_fn(X_ji_batch, C_j_batch, Z_ji_batch, lengths)\n",
    "\n",
    "            total_neural_net_loss +=  neural_net_loss.item()\n",
    "            total_glm_loss += glm_loss.item()\n",
    "            \n",
    "            # store all predictions in list\n",
    "            neural_net_zeta.append(torch.exp(outputs.cpu()[0]))\n",
    "            glm_zeta.append(batch['Z_ji'][0])\n",
    "    \n",
    "    # calculate average loss across all batches\n",
    "    avg_neural_net_loss = total_neural_net_loss / len(loader)\n",
    "    avg_glm_loss = total_glm_loss / len(loader)\n",
    "    \n",
    "    neural_net_zeta = torch.cat(neural_net_zeta, dim=0)\n",
    "    glm_zeta = torch.cat(glm_zeta, dim=0)\n",
    "    \n",
    "    return avg_neural_net_loss, avg_glm_loss, neural_net_zeta, glm_zeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, loss_fn):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for idx, batch in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "        Y_ji_batch = batch['Y_ji'].to(device)\n",
    "        X_ji_batch = batch['X_ji'].to(device)\n",
    "        C_j_batch = batch['C_j'].to(device)\n",
    "        lengths = batch['gene_length'].to(device)\n",
    "        \n",
    "        outputs = model(Y_ji_batch)\n",
    "        loss = loss_fn(X_ji_batch, C_j_batch, outputs.squeeze(2), lengths)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # calculate average loss across all batches\n",
    "        total_loss += loss.item()\n",
    "    avg_train_loss = total_loss / len(loader)\n",
    "    \n",
    "    return avg_train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomLoss, self).__init__()\n",
    "\n",
    "    def forward(self, X_ji, C_j, rho_ji, lengths):\n",
    "        C_j_value = C_j[0]\n",
    "        loss = X_ji * rho_ji + C_j_value * torch.exp(-rho_ji) - X_ji * torch.log(C_j_value)\n",
    "        \n",
    "        # normalize loss by sequence length\n",
    "        loss_sum = loss.sum(dim=1)\n",
    "        normalized_loss = loss_sum / lengths.float()\n",
    "        \n",
    "        # calculate average loss within each batch\n",
    "        return (normalized_loss).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_profiler_results(profiler):\n",
    "    # Sort by CUDA memory usage if using CUDA, else sort by CPU memory usage\n",
    "    sort_by_key = \"cuda_memory_usage\" if torch.cuda.is_available() else \"cpu_memory_usage\"\n",
    "    print(profiler.key_averages().table(sort_by=sort_by_key, row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model configs\n",
    "model_type = 'linear'\n",
    "num_layers = 1\n",
    "hidden_layer_size = 100\n",
    "bidirectional = False\n",
    "weight_init = None\n",
    "\n",
    "# dataset configs\n",
    "train_batch_size=50\n",
    "train_use_sliding_window = True\n",
    "train_window_size = 500\n",
    "train_stride = 500\n",
    "val_batch_size=50\n",
    "val_use_sliding_window = True\n",
    "val_window_size = 500\n",
    "val_stride = 500\n",
    "\n",
    "# optimizer configs\n",
    "learning_rate = 1e-3\n",
    "optimizer = 'adam'\n",
    "momentum = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "epochs = 20\n",
    "\n",
    "def train():\n",
    "    model = build_model(model_type, num_layers, hidden_layer_size, bidirectional, weight_init)\n",
    "    train_loader = build_dataset(train_data, batch_size, use_sliding_window, window_size, stride) # if window size = stride, then no data overlap\n",
    "    valid_loader = build_dataset(valid_data, batch_size, use_sliding_window, window_size, stride)\n",
    "    optimizer = build_optimizer(model, optimizer, learning_rate, momentum)\n",
    "    \n",
    "    loss_fn = CustomLoss()\n",
    "    # track loss curves\n",
    "    loss_neural_net_train = [0] * epochs\n",
    "    loss_neural_net_valid = [0] * epochs\n",
    "    loss_glm_valid = [0] * epochs\n",
    "    \n",
    "    # scheduler to reduce learning rate by half when new validation loss > old validation loss\n",
    "    old_train_loss = float('inf')\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=1, verbose=True)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f'Epoch {epoch+1}')\n",
    "        \n",
    "        train_loss = train_epoch(model, train_loader, optimizer, loss_fn)\n",
    "        loss_neural_net_train[epoch] = train_loss\n",
    "        print(\"train loss: \"+ str(train_loss))\n",
    "        \n",
    "        valid_neural_net_loss, valid_glm_loss, neural_net_zeta, glm_zeta = valid_epoch(model, valid_loader, loss_fn)\n",
    "        loss_neural_net_valid[epoch] = valid_neural_net_loss\n",
    "        loss_glm_valid[epoch] = valid_glm_loss\n",
    "        print(\"valid neural net loss: \"+ str(valid_neural_net_loss))\n",
    "        print(\"valid glm loss: \"+ str(valid_glm_loss))\n",
    "        \n",
    "        # compute metrics\n",
    "        mae = F.l1_loss(neural_net_zeta.squeeze(), glm_zeta)\n",
    "        mse = F.mse_loss(neural_net_zeta.squeeze(), glm_zeta)\n",
    "        correlation_coefficient = np.corrcoef(glm_zeta, neural_net_zeta.squeeze())[0, 1]\n",
    "        print(\"Correlation Coefficient:\", correlation_coefficient)\n",
    "        print(f\"Mean Absolute Error: {mae.item():.4f}\")\n",
    "        print(f\"Mean Squared Error: {mse.item():.4f}\")\n",
    "        \n",
    "        # reduce learning rate if new loss > old loss\n",
    "        if train_loss > old_train_loss:\n",
    "            optimizer.param_groups[0]['lr'] *= 0.5\n",
    "            print(f\"Reduced learning rate to {optimizer.param_groups[0]['lr']}\")\n",
    "        old_train_loss = train_loss\n",
    "        scheduler.step(train_loss)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=12, out_features=1, bias=False)\n",
      "Model is on device: cuda:0\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.0995160642368273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid neural net loss: 0.07899529055423675\n",
      "valid glm loss: 0.08575789211631307\n",
      "Correlation Coefficient: 0.9202179054737801\n",
      "Mean Absolute Error: 0.0252\n",
      "Mean Squared Error: 0.0023\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.09914669207468142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid neural net loss: 0.07893172217865303\n",
      "valid glm loss: 0.08575789211631307\n",
      "Correlation Coefficient: 0.9147447130964103\n",
      "Mean Absolute Error: 0.0380\n",
      "Mean Squared Error: 0.0034\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.09913626049187266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid neural net loss: 0.078943723073286\n",
      "valid glm loss: 0.08575789211631307\n",
      "Correlation Coefficient: 0.8928622352922888\n",
      "Mean Absolute Error: 0.0354\n",
      "Mean Squared Error: 0.0038\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.09913070751288242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid neural net loss: 0.07893595315360671\n",
      "valid glm loss: 0.08575789211631307\n",
      "Correlation Coefficient: 0.885518634734096\n",
      "Mean Absolute Error: 0.0366\n",
      "Mean Squared Error: 0.0041\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.09913132049897252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid neural net loss: 0.07893922108044539\n",
      "valid glm loss: 0.08575789211631307\n",
      "Correlation Coefficient: 0.8780729964494681\n",
      "Mean Absolute Error: 0.0361\n",
      "Mean Squared Error: 0.0043\n",
      "Reduced learning rate to 0.0005\n",
      "Epoch     5: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.09910888135813128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid neural net loss: 0.07892044498676822\n",
      "valid glm loss: 0.08575789211631307\n",
      "Correlation Coefficient: 0.8984238472489788\n",
      "Mean Absolute Error: 0.0376\n",
      "Mean Squared Error: 0.0038\n",
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.09910103325413175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid neural net loss: 0.07891342918829745\n",
      "valid glm loss: 0.08575789211631307\n",
      "Correlation Coefficient: 0.9111506354848782\n",
      "Mean Absolute Error: 0.0377\n",
      "Mean Squared Error: 0.0035\n",
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.0990999689857009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid neural net loss: 0.0789114656455797\n",
      "valid glm loss: 0.08575789211631307\n",
      "Correlation Coefficient: 0.9194799089687167\n",
      "Mean Absolute Error: 0.0372\n",
      "Mean Squared Error: 0.0032\n",
      "Epoch     8: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.09909358054836058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid neural net loss: 0.07891010832722935\n",
      "valid glm loss: 0.08575789211631307\n",
      "Correlation Coefficient: 0.924074174773945\n",
      "Mean Absolute Error: 0.0370\n",
      "Mean Squared Error: 0.0031\n",
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.09909326475724019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid neural net loss: 0.07890925341052904\n",
      "valid glm loss: 0.08575789211631307\n",
      "Correlation Coefficient: 0.9279262155497126\n",
      "Mean Absolute Error: 0.0368\n",
      "Mean Squared Error: 0.0029\n",
      "Epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.09909303866960843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid neural net loss: 0.0789087430861555\n",
      "valid glm loss: 0.08575789211631307\n",
      "Correlation Coefficient: 0.9310504868280014\n",
      "Mean Absolute Error: 0.0365\n",
      "Mean Squared Error: 0.0028\n",
      "Epoch    11: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.09908968976624584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid neural net loss: 0.07890834885926784\n",
      "valid glm loss: 0.08575789211631307\n",
      "Correlation Coefficient: 0.932709119069659\n",
      "Mean Absolute Error: 0.0364\n",
      "Mean Squared Error: 0.0028\n",
      "Epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.0990895890728282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid neural net loss: 0.07890802485771575\n",
      "valid glm loss: 0.08575789211631307\n",
      "Correlation Coefficient: 0.9342208430109944\n",
      "Mean Absolute Error: 0.0363\n",
      "Mean Squared Error: 0.0027\n",
      "Epoch    13: reducing learning rate of group 0 to 3.1250e-05.\n",
      "Epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.09908791449338888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid neural net loss: 0.0789078396713746\n",
      "valid glm loss: 0.08575789211631307\n",
      "Correlation Coefficient: 0.9349990243268043\n",
      "Mean Absolute Error: 0.0363\n",
      "Mean Squared Error: 0.0027\n",
      "Epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.09908786591493522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid neural net loss: 0.07890766999223447\n",
      "valid glm loss: 0.08575789211631307\n",
      "Correlation Coefficient: 0.9357443206842775\n",
      "Mean Absolute Error: 0.0362\n",
      "Mean Squared Error: 0.0027\n",
      "Epoch    15: reducing learning rate of group 0 to 1.5625e-05.\n",
      "Epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.09908702493554541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid neural net loss: 0.0789075802421117\n",
      "valid glm loss: 0.08575789211631307\n",
      "Correlation Coefficient: 0.936122547862855\n",
      "Mean Absolute Error: 0.0362\n",
      "Mean Squared Error: 0.0027\n",
      "Epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.09908700082634131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid neural net loss: 0.07890749410355276\n",
      "valid glm loss: 0.08575789211631307\n",
      "Correlation Coefficient: 0.9364930826536381\n",
      "Mean Absolute Error: 0.0362\n",
      "Mean Squared Error: 0.0026\n",
      "Epoch    17: reducing learning rate of group 0 to 7.8125e-06.\n",
      "Epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.09908657903496626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid neural net loss: 0.07890744989300326\n",
      "valid glm loss: 0.08575789211631307\n",
      "Correlation Coefficient: 0.9366797717655555\n",
      "Mean Absolute Error: 0.0361\n",
      "Mean Squared Error: 0.0026\n",
      "Epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.09908656697873565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid neural net loss: 0.07890740655093857\n",
      "valid glm loss: 0.08575789211631307\n",
      "Correlation Coefficient: 0.9368646164201145\n",
      "Mean Absolute Error: 0.0361\n",
      "Mean Squared Error: 0.0026\n",
      "Epoch    19: reducing learning rate of group 0 to 3.9063e-06.\n",
      "Epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.09908635570513322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid neural net loss: 0.07890738460380245\n",
      "valid glm loss: 0.08575789211631307\n",
      "Correlation Coefficient: 0.936957401978495\n",
      "Mean Absolute Error: 0.0361\n",
      "Mean Squared Error: 0.0026\n"
     ]
    }
   ],
   "source": [
    "model = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model parameters\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\"\"\"\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "filename = f\"models/LSTM_Elongation_Model.pth\"\n",
    "torch.save(model.state_dict(), filename)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model state\n",
    "\n",
    "\"\"\"\n",
    "model = build_model(model_type, num_layers, hidden_layer_size, bidirectional, weight_init)\n",
    "\n",
    "model.load_state_dict(torch.load(\"models/Elongation_Model.pth\"))\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(\"CUDA (GPU support) is available:\", cuda_available)\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(\"Number of GPUs available:\", num_gpus)\n",
    "if cuda_available:\n",
    "    if num_gpus > 1:\n",
    "        print(\"Using\", num_gpus, \"GPUs\")\n",
    "        model = torch.nn.DataParallel(model)\n",
    "    model = model.to('cuda')\n",
    "\n",
    "first_param_device = next(model.parameters()).device\n",
    "print(\"Model is on device:\", first_param_device)\n",
    "\n",
    "model.double()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"ctcf\": 0.0031987207283796625, \"h3k36me3\": -0.12421152667978225, \"h3k4me1\": -0.021062086373569593, \"h3k79me2\": -0.0389832792639541, \"h3k9me1\": -0.05266693797386992, \"h3k9me3\": -0.026519421964241254, \"h4k20me1\": -0.027763096636773142, \"sj5\": -0.018723344581300327, \"sj3\": -0.04029743818548164, \"dms\": -0.07932229215236103, \"wgbs\": -0.16842686394812184, \"rpts\": 0.020859243197197813\n"
     ]
    }
   ],
   "source": [
    "weights = model.weight.data.cpu().numpy()\n",
    "combined = ', '.join([f'\"{s}\": {f}' for s, f in zip(feature_names, weights[0])])\n",
    "print(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_kappa = [-0.0224536145637661, -0.094592589, -0.023815382, 0.030402922, -0.067234092, -0.032196914, -0.040911478, -0.018557168, -0.033545905, -0.051103287, -0.204434712, 0.015831043]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "GLM K\n",
    "\n",
    "* ctcf: -0.02\n",
    "* h3k36me3: -0.09\n",
    "* h3k4me1: -0.02\n",
    "* h3k79me2: +0.03\n",
    "* h3k9me1: -0.06\n",
    "* h3k9me3: -0.03\n",
    "* h4k20me1: -0.04\n",
    "* sj5: -0.02\n",
    "* sj3: -0.03\n",
    "* dms->stem-loop: -0.05\n",
    "* rpts->low-complex: +0.01\n",
    "* wgbs->DNAm: -0.2\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss curve\n",
    "\n",
    "epochs = range(1, len(loss_neural_net_train) + 1)\n",
    "plt.plot(epochs, loss_neural_net_train, label='train_neural_net_loss')\n",
    "plt.plot(epochs, loss_neural_net_valid, label='valid_neural_net_loss')\n",
    "plt.plot(epochs, loss_glm_valid, label='valid_glm_loss')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(glm_zeta, net_zeta):\n",
    "    indices = range(len(glm_zeta))\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    \n",
    "    ax.scatter(indices, net_zeta, color='blue', label='Neural Net Zeta', s=10, alpha=0.5)\n",
    "    ax.scatter(indices, glm_zeta, color='orange', label='GLM Zeta', s=10, alpha=0.5)\n",
    "    \n",
    "    ax.set_title('Neural Net vs GLM Elongation Rate')\n",
    "    ax.set_xlabel('Index')\n",
    "    ax.set_ylabel('Elongation Rate')\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.ylim(0.5, 1.3)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "test_dataset = GeneDataset(test_data, False)\n",
    "tstdl = DataLoader(test_dataset, batch_size=1)\n",
    "data_iter = iter(tstdl)\n",
    "\n",
    "# plot for subset of genes in test dataset\n",
    "for i in range(0, 4):\n",
    "    inputs = next(data_iter) \n",
    "    print(\"number of samples: \" + str(len(inputs)))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_inputs = inputs['Y_ji'].to(device)\n",
    "        rho_ji = model(y_inputs)\n",
    "        print(rho_ji)\n",
    "\n",
    "    glm_zeta = inputs['Z_ji'][0]\n",
    "    # convert log(Z) outputs to Z\n",
    "    net_zeta = torch.exp(rho_ji.cpu().squeeze())\n",
    "    \n",
    "    plot_data(glm_zeta, net_zeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute metrics for test dataset\n",
    "\n",
    "net_zeta = []\n",
    "glm_zeta = []\n",
    "with torch.no_grad():\n",
    "    for batch in tstdl:\n",
    "        y_inputs = batch['Y_ji'].to(device)\n",
    "        rho_ji = model(y_inputs)\n",
    "        # convert log(Z) outputs to Z\n",
    "        net_zeta.append(torch.exp(rho_ji.cpu()[0]))\n",
    "        glm_zeta.append(batch['Z_ji'][0])\n",
    "\n",
    "net_zeta = torch.cat(net_zeta, dim=0)\n",
    "glm_zeta = torch.cat(glm_zeta, dim=0)\n",
    "mae = F.l1_loss(net_zeta.squeeze(), glm_zeta)\n",
    "mse = F.mse_loss(net_zeta.squeeze(), glm_zeta)\n",
    "\n",
    "correlation_coefficient = np.corrcoef(glm_zeta, net_zeta.squeeze())[0, 1]\n",
    "print(\"Correlation Coefficient:\", correlation_coefficient)\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae.item():.4f}\")\n",
    "print(f\"Mean Squared Error: {mse.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def density_plot(glm_zeta, net_zeta, gene_id):\n",
    "    sns.kdeplot(x=glm_zeta, y=net_zeta, fill=True, cmap=\"Blues\")\n",
    "            \n",
    "    plt.xlim([min(glm_zeta), max(glm_zeta)])\n",
    "    plt.ylim([min(net_zeta), max(net_zeta)])\n",
    "\n",
    "\n",
    "    plt.xlabel('GLM Elongation Rate')\n",
    "    plt.ylabel('Neural Net Elongation Rate')\n",
    "    plt.title(gene_id)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatterplot(net_zeta, glm_zeta, gene_id):\n",
    "    indices = range(len(glm_zeta))\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    \n",
    "    min_val = min(min(net_zeta), min(glm_zeta))\n",
    "    max_val = max(max(net_zeta), max(glm_zeta))\n",
    "\n",
    "    plt.xlim(min_val, max_val)\n",
    "    plt.ylim(min_val, max_val)\n",
    "    \n",
    "    ax.scatter(net_zeta, glm_zeta, s=5)\n",
    "    \n",
    "    ax.set_title(gene_id)\n",
    "    ax.set_xlabel('Neural Net Zeta')\n",
    "    ax.set_ylabel('GLM Zeta')\n",
    "    ax.legend()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot for all genes in test dataset\n",
    "\n",
    "total_loss = 0\n",
    "loss_fn = CustomLoss()\n",
    "for batch in tstdl:\n",
    "    gene_id = batch['GeneId'][0]\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_inputs = batch['Y_ji'].to(device)\n",
    "        rho_ji = model(y_inputs)\n",
    "        loss = loss_fn(batch['X_ji'], batch['C_j'], rho_ji)\n",
    "    \n",
    "    total_loss += loss.item()\n",
    "\n",
    "    glm_zeta = batch['Z_ji'][0]\n",
    "    # convert log(Z) outputs to Z\n",
    "    net_zeta = torch.exp(rho_ji.cpu().squeeze())\n",
    "        \n",
    "    #density_plot(glm_zeta, net_zeta, gene_id)\n",
    "        \n",
    "    #scatterplot(predicted_zeta, simulated_zeta, gene_id)\n",
    "        \n",
    "    #plot_data(glm_zeta, net_zeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot scatterplot of neural net weights and glm weights\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "sns.scatterplot(x=glm_kappa, y=weights[0])\n",
    "\n",
    "for i in range(len(glm_kappa)):\n",
    "    plt.text(glm_kappa[i], weights[0][i], feature_names[i], fontsize=13, ha='right', va='top')\n",
    "plt.xlabel('GLM Weights')\n",
    "plt.ylabel('Neural Net Weights')\n",
    "\n",
    "max_val = max(np.max(glm_kappa), np.max(weights[0])) + 0.04\n",
    "min_val = min(np.min(glm_kappa), np.min(weights[0])) - 0.04\n",
    "\n",
    "plt.xlim(max_val, min_val)\n",
    "plt.ylim(max_val, min_val)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profiling code\n",
    "\"\"\"\n",
    "def print_profiler_results(profiler):\n",
    "    print(profiler.key_averages().table(sort_by=\"self_cpu_time_total\", row_limit=10))\n",
    "\n",
    "with torch.profiler.profile(\n",
    "    activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA],\n",
    "    schedule=torch.profiler.schedule(wait=1, warmup=1, active=3),\n",
    "    on_trace_ready=print_profiler_results,\n",
    "    record_shapes=True,\n",
    "    profile_memory=True\n",
    ") as profiler:\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}')\n",
    "        model.train()\n",
    "        trndl = DataLoader(train_set, batch_size=batch_size, num_workers=7, shuffle=False, pin_memory=True)\n",
    "        for i, batch in enumerate(trndl):\n",
    "            optimizer.zero_grad()\n",
    "            Y_ji_batch = batch['Y_ji'].to(device)\n",
    "            X_ji_batch = batch['X_ji'].to(device)\n",
    "            C_j_batch = batch['C_j'].to(device)\n",
    "            outputs = model(Y_ji_batch)\n",
    "            loss = loss_fn(X_ji_batch, C_j_batch, outputs)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_hist_train[epoch] += loss.item()\n",
    "            profiler.step()\n",
    "        loss_hist_train[epoch] /= len(trndl)\n",
    "        del trndl\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda3 (Python 3.7.6)",
   "language": "python",
   "name": "anaconda3_2020.02"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
